### Шанс вопроса: 3%

Когда я работал над проектом, мы активно использовали Docker для создания изолированных окружений для наших приложений. Это позволяло нам легко управлять зависимостями и упрощало процесс развертывания. Мы создавали Dockerfile для каждого компонента проекта, где определяли базовые образы и устанавливали все необходимые зависимости с помощью инструкций Docker.

Например, для одного из наших проектов мы создали файл `Dockerfile` следующего вида:

```dockerfile
# Используем базовый образ Python
FROM python:3.9-slim

# Устанавливаем рабочую директорию внутри контейнера
WORKDIR /app

# Копируем requirements.txt в контейнер
COPY requirements.txt .

# Устанавливаем зависимости
RUN pip install -r requirements.txt

# Копируем остальные файлы проекта в контейнер
COPY . .

# Команды для запуска приложения
CMD ["python", "app.py"]
```

Этот Dockerfile устанавливает базовый образ Python, копирует файл `requirements.txt` и устанавливает все необходимые библиотеки, а затем копирует весь проект в контейнер. Запуск приложения осуществляется командой `python app.py`.

Мы также использовали Docker Compose для определения и запуска нескольких контейнеров, необходимых для работы нашего приложения. Например, файл `docker-compose.yml` мог выглядеть следующим образом:

```yaml
version: '3'
services:
  web:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    depends_on:
      - db

  db:
    image: postgres:latest
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
```

Этот файл определяет два сервиса: `web` и `db`. Сервис `web` использует Dockerfile для сборки образа, а сервис `db` запускает PostgreSQL из официального образа Docker. Мы также настроили порт 8000 в контейнере `web` для доступа к приложению через хост-машину.

Использование Docker позволило нам упростить развертывание и тестирование, а также обеспечило повторяемость окружения между разработчиками и серверами.