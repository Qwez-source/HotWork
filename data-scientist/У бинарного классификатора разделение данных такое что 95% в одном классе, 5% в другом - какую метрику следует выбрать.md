### Шанс вопроса: 14%

Для задачи с сильно несбалансированными данными, где один класс занимает 95%, а другой — 5%, наиболее подходящей метрикой является **F1-score** или **AUC-ROC**.

### F1-Score
F1-Score учитывает как точность (precision), так и полноту (recall). Он рассчитывается по формуле:
\[ \text{F1} = 2 \times \frac{\text{precision} \times \text{recall}}{\text{precision} + \text{recall}} \]
Где:
- **Precision** (точность) — это доля истинно положительных результатов среди всех результатов, предсказанных как положительные.
\[ \text{Precision} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive}} \]
- **Recall** (полнота) — это доля истинно положительных результатов среди всех фактически положительных результатов.
\[ \text{Recall} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}} \]

### AUC-ROC (Area Under the Receiver Operating Characteristic Curve)
AUC-ROC — это вероятность того, что случайно выбранный положительный пример будет классифицирован как положительный и у него будет более высокий рейтинг, чем случайно выбранный отрицательный пример. Для несбалансированных данных AUC-ROC может быть полезным показателем, так как он менее чувствителен к дисбалансу классов, чем точность или F1-score.

### Пример кода на Python для оценки модели с использованием F1-Score и AUC-ROC:
```python
from sklearn.metrics import f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import numpy as np

# Пример данных
X = np.random.rand(100, 20)  # 100 примеров, 20 признаков
y = np.concatenate([np.zeros(95), np.ones(5)])  # 95 нулей и 5 единиц

# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Создание модели
model = LogisticRegression()
model.fit(X_train, y_train)

# Предсказание
y_pred = model.predict(X_test)

# Оценка F1-Score и AUC-ROC
f1 = f1_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred)

print("F1-Score:", f1)
print("AUC-ROC:", auc_roc)
```

Этот код демонстрирует, как можно использовать F1-Score и AUC-ROC для оценки модели классификации. Обратите внимание, что в этом примере данные сильно несбалансированы, поэтому важно использовать метрики, которые учитывают дисбаланс.