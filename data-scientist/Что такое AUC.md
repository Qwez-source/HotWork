### Шанс вопроса: 14%

AUC (Area Under the Curve) — это метрика, которая используется для оценки производительности бинарных классификаторов. Она представляет собой площадь под кривой ROC (Receiver Operating Characteristic). Кривая ROC строится путем изменения порога классификации от 0 до 1, и на каждом шаге вычисляются два параметра: True Positive Rate (TPR) и False Positive Rate (FPR). TPR показывает долю истинно положительных случаев, а FPR — долю ложноположительных.

AUC имеет значение от 0.5 до 1. Значение 0.5 означает, что классификатор не лучше случайного угадывания, в то время как значение 1 означает идеальную классификацию. Чем выше AUC, тем лучше модель способна различать положительные и отрицательные примеры.

Пример расчета AUC с использованием Python:
```python
from sklearn import metrics
import numpy as np

# Предположим, что y_true — это массив меток реальных классов, а y_scores — массив вероятностей класса 1
y_true = [0, 0, 1, 1]
y_scores = [0.1, 0.4, 0.35, 0.8]

# Вычисляем AUC
auc_score = metrics.roc_auc_score(y_true, y_scores)
print("AUC:", auc_score)
```
Этот код вычислит AUC для данных с двумя отрицательными и двумя положительными примерами.