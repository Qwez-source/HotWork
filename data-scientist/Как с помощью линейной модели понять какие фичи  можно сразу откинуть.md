### Шанс вопроса: 14%

Для оценки важности признаков в линейной модели, такой как линейная регрессия или логистическая регрессия, можно использовать различные методы, включая статистические тесты и анализ корреляции. Вот несколько подходов:

1. **Статистический тест Вальда (Wald Test)**: Этот тест позволяет оценить значимость отдельных коэффициентов модели. Если p-value для какого-либо признака выше уровня значимости (обычно 0.05), это может быть индикатором того, что данный признак незначимо отличается от нуля и его можно рассмотреть для удаления.

2. **Визуальный анализ остатков**: Визуализация остатков (разницы между предсказанными и фактическими значениями) может помочь идентифицировать признаки, которые плохо соответствуют модели. Сильные закономерности или аномальные наблюдения в остатках могут указывать на важность признака.

3. **Частичная корреляция**: Можно рассчитать частичную корреляцию между каждым признаком и целевой переменной, контролируя влияние других признаков. Если частичная корреляция близка к нулю, это может указывать на то, что данный признак не имеет сильного линейного отношения с целевой переменной и его можно рассмотреть для удаления.

4. **Включение и исключение по очереди**: Модель можно обучать, включая и исключая каждый признак по очереди. Если коэффициент при некотором признаке становится незначительным или даже меняет знак после исключения, это может указывать на его важность для модели.

5. **Метод главных компонент (PCA)**: Этот метод может помочь визуализировать и количественно оценить взаимосвязь между признаками. Высокое собственное значение, соответствующее главной компоненте, связанной с большим количеством дисперсии в данных, может указывать на важность исходных признаков.

Пример кода на Python для иллюстрации:
```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Загрузка данных
data = pd.read_csv('data.csv')
X = data.drop('target', axis=1)
y = data['target']

# Обучение модели логистической регрессии
model = LogisticRegression()
model.fit(X, y)

# Статистический тест Вальда для оценки значимости признаков
p_values = model.coef_[0] / np.sqrt(np.diag(model.cov_params()))
p_values = 2 * (1 - stats.norm.cdf(abs(p_values)))
significant_features = X.columns[p_values < 0.05]

# Визуальный анализ остатков
residuals = y - model.predict(X)
plt.scatter(model.predict(X), residuals)
plt.axhline(y=0, color='r', linestyle='-')
plt.show()

# Включение и исключение по очереди (пример для первого признака)
initial_model = LogisticRegression().fit(X, y)
initial_score = initial_model.score(X, y)

for feature in X.columns:
    temp_X = X.drop(feature, axis=1)
    temp_model = LogisticRegression().fit(temp_X, y)
    if temp_model.score(temp_X, y) < initial_score:
        print(f"Feature {feature} is important")
```

Этот код демонстрирует несколько методов оценки важности признаков в линейной модели, включая статистический тест Вальда и визуальный анализ остатков.