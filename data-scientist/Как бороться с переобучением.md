### Шанс вопроса: 14%

Переобучение - это когда модель обучается настолько хорошо на тренировочных данных, что она начинает предсказывать их идеально, но плохо обобщается на новые, непредвиденные данные. Для борьбы с переобучением можно использовать следующие методы:

1. **Увеличение размера обучающей выборки**: Чем больше данных используется для обучения, тем лучше модель сможет обобщаться на новые данные. Это может включать сбор дополнительных данных или использование методов синтетической выборки (например, SMOTE для классификации).

2. **Регуляризация**: Методы регуляризации ограничивают сложность модели, что помогает предотвратить переобучение. Наиболее распространенными методами являются L1 (LASSO) и L2 (Ridge) регуляризация.

3. **Уменьшение числа признаков**: Если у модели слишком много признаков, она может запомнить шум в данных, вместо того чтобы учиться извлекать полезные характеристики. Можно использовать методы отбора признаков (feature selection) или применять модели более высокого порядка, которые автоматически уменьшают количество признаков.

4. **Кросс-валидация**: Разбивая данные на несколько частей и обучая модель на разных комбинациях этих частей, можно оценить, как хорошо модель обобщается. Это помогает выявить переобучение путем сравнения производительности модели на различных подмножествах данных.

5. **Уменьшение степени полинома**: При использовании методов машинного обучения, таких как линейная регрессия или метод опорных векторов (SVM), увеличение степени полинома может привести к переобучению. Поэтому важно подобрать оптимальную степень полинома.

Пример кода на Python для регуляризации в случае линейной регрессии:

```python
from sklearn.linear_model import Ridge
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Генерация данных
X, y = make_regression(n_samples=100, n_features=20, noise=0.5, random_state=42)

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Создание модели с регуляризацией L2 (Ridge Regression)
model = Ridge(alpha=1.0)  # alpha - параметр регуляризации

# Обучение модели
model.fit(X_train, y_train)

# Предсказание на тестовых данных
y_pred = model.predict(X_test)

# Визуализация результатов (необязательно)
plt.scatter(y_test, y_pred)
plt.xlabel("True Values")
plt.ylabel("Predicted Values")
plt.title("Ridge Regression: True vs Predicted")
plt.show()
```

Этот код демонстрирует использование регуляризации (в данном случае, Ridge regression) для борьбы с переобучением.