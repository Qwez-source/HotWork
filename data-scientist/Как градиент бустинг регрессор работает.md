### Шанс вопроса: 42%

Градиентный бустинг — это метод машинного обучения, который создаёт сильную модель из слабых моделей. Он строит последовательность моделей, каждая из которых пытается улучшить предсказания предыдущей. Основная идея заключается в том, чтобы сделать последовательные предсказания, где каждое следующее предсказание исправляет ошибки предыдущих.

В случае градиентного бустинга регрессора, цель состоит в том, чтобы минимизировать функцию потерь, которая обычно является среднеквадратической ошибкой или другой подходящей метрикой. Градиентный бустинг регрессора использует метод градиентного спуска для нахождения оптимальных значений весов, что позволяет улучшить точность предсказаний.

Пример реализации на Python с использованием библиотеки `GradientBoostingRegressor` из пакета `sklearn`:

```python
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import numpy as np

# Создаем и обучаем модель
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([1, 2, 3, 4, 5])

model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1)
model.fit(X, y)

# Предсказание значений
y_pred = model.predict(X)

# Оценка модели
mse = mean_squared_error(y, y_pred)
print("Mean Squared Error:", mse)
```

В этом примере создается модель градиентного бустинга регрессора с 100 деревьями (n_estimators), где каждое следующее дерево пытается исправить ошибки предыдущих. Параметр `learning_rate` определяет, насколько сильно модель будет корректировать свои предсказания на каждом шаге.