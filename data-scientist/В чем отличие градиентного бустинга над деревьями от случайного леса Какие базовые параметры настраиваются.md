### Шанс вопроса: 14%

Градиентный бустинг (Gradient Boosting) и случайный лес (Random Forest) являются мощными методами машинного обучения, которые используются для улучшения предсказательной способности моделей. Они отличаются способом построения композиции моделей и параметрами настройки.

**Градиентный бустинг:**
- **Основная идея**: Градиентный бустинг строит последовательность моделей, где каждая следующая модель пытается исправить ошибки предыдущей. Он работает с регрессионными задачами и использует градиентный спуск для минимизации функционала потерь.
- **Тип модели**: Обычно используются деревья решений в качестве базовых моделей, хотя могут быть и другие типы моделей (например, линейные модели).
- **Параметры настройки**: Важные параметры включают:
  - `n_estimators`: Число базовых моделей, которые будут построены.
  - `learning_rate`: Шаг обучения, который определяет скорость обучения модели.
  - `max_depth`: Максимальная глубина дерева решений.
- **Пример на Python (с использованием библиотеки `GradientBoostingRegressor` из `sklearn`)**:
  ```python
  from sklearn.ensemble import GradientBoostingRegressor
  model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)
  model.fit(X_train, y_train)
  ```

**Случайный лес:**
- **Основная идея**: Случайный лес создает множество деревьев решений и усредняет их прогнозы для улучшения точности. Каждое дерево строится на случайно выбранных подмножествах данных и признаков.
- **Тип модели**: Деревья решений в качестве базовых моделей.
- **Параметры настройки**: Важные параметры включают:
  - `n_estimators`: Число деревьев в лесу.
  - `max_depth`: Максимальная глубина каждого дерева.
  - `max_features`: Количество признаков, которые могут быть использованы при построении каждого дерева.
- **Пример на Python (с использованием библиотеки `RandomForestRegressor` из `sklearn`)**:
  ```python
  from sklearn.ensemble import RandomForestRegressor
  model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)
  model.fit(X_train, y_train)
  ```

**Основные отличия:**
- **Построение моделей**: Градиентный бустинг строит последовательность моделей, улучшая предсказания с каждой новой моделью, в то время как случайный лес создает множество независимых деревьев и усредняет их результаты.
- **Влияние ошибок**: Градиентный бустинг концентрируется на минимизации ошибок предыдущей модели, тогда как случайный лес фокусируется на уменьшении дисперсии и повышении обобщающей способности.
- **Параметры**: Градиентный бустинг более чувствителен к параметрам, таким как `learning_rate` и `max_depth`, тогда как случайный лес может работать достаточно хорошо даже при значениях по умолчанию для многих параметров.

Эти методы имеют свои особенности и могут быть адаптированы под конкретные задачи машинного обучения.