### Шанс вопроса: 14%

Бэкпропгайшн, или Backpropagation, является ключевым алгоритмом для обучения нейронных сетей. Он используется в машинном обучении и глубоком обучении для корректировки весов синапсов между нейронами таким образом, чтобы минимизировать разницу между предсказанием модели и фактическими значениями.

Алгоритм бэкпропагации работает следующим образом:
1. **Прямой проход (Forward Pass)**: Входной сигнал подаётся на вход нейронной сети, и он проходит через каждый слой нейронов, завершаясь на выходе. На этом этапе рассчитываются значения активации для каждого нейрона.
2. **Обратное распространение ошибки (Backward Pass)**: Ошибка между предсказанием и фактическим значением вычисляется и передаётся от выхода к входу сети. Эта ошибка используется для корректировки весов синапсов так, чтобы уменьшить разницу между предсказанием и фактическими данными.

**Пример кода на Python**:
```python
import numpy as np

# Сигмоидная функция
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Производная сигмоидной функции
def sigmoid_derivative(x):
    return x * (1 - x)

# Инициализация весов случайным образом
np.random.seed(1)
weights = 2 * np.random.random((3, 1)) - 1

for iteration in range(1000):
    # Входные данные
    inputs = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])
    # Ожидаемые выходы
    outputs = np.array([[0], [1], [1], [0]]).T

    # Прямой проход
    layer_inputs = inputs
    layer_outputs = sigmoid(layer_inputs)
    
    # Вычисление ошибки
    error = outputs - layer_outputs
    
    # Обратное распространение ошибки (корректировка весов)
    adjustments = error * sigmoid_derivative(layer_outputs)
    weight_adjustments = np.dot(inputs.T, adjustments)
    weights += weight_adjustments
```

Этот пример демонстрирует базовую нейронную сеть с одним скрытым слоем и сигмоидными функциями активации. Алгоритм бэкпропагации корректирует веса синапсов для улучшения предсказаний модели.