### Шанс вопроса: 14%

Прунинг деревьев (tree pruning) — это процесс сокращения или удаления ветвей дерева, что позволяет улучшить структуру данных и повысить производительность. Это может быть необходимо для решения различных задач, таких как управление памятью, оптимизация запросов к базе данных или устранение шума в данных.

Прунинг деревьев решений (decision tree pruning) обычно включает следующие шаги:

1. **Обучение модели без прунинга**: Сначала обучаем дерево решений на всем доступном наборе данных. Это позволяет дереву формироваться и развиваться максимально точно, что может привести к переобучению или чрезмерному увеличению сложности модели.

2. **Оценка модели**: Используем внешнюю метрику (например, ошибка на обучающем или тестовом наборе данных) для оценки качества модели. Это помогает понять, насколько хорошо модель соответствует данным и как она обобщается на новые примеры.

3. **Прунинг дерева**: После обучения оцениваем важность каждой ветви дерева. Ветви с низкой важностью (или те, которые не дают существенного улучшения модели) удаляются. Это может быть достигнуто путем ограничения максимальной глубины дерева, минимального количества образцов в листе (leaf node), или других критериев качества.

4. **Оценка после прунинга**: После удаления ветвей модель переобучается или становится слишком упрощенной, если это произошло. Снова оцениваем модель на основе внешних критериев, чтобы определить, улучшилось ли качество после прунинга.

Пример кода для прунинга дерева решений в Python с использованием библиотеки scikit-learn:

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import export_text

# Загрузка данных
data = load_iris()
X = data.data
y = data.target

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Обучение дерева решений без прунинга
tree = DecisionTreeClassifier(random_state=42)
tree.fit(X_train, y_train)

# Оценка модели до прунинга
y_pred_before = tree.predict(X_test)
print("Accuracy before pruning:", accuracy_score(y_test, y_pred_before))

# Экспорт текста дерева решений для визуализации или анализа
r = export_text(tree, feature_names=data.feature_names.tolist())
print("Decision tree before pruning:\n", r)

# Прунинг дерева решений
path = tree.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path['ccp_alphas']
clfs = []
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

# Оценка модели после прунинга
y_preds = [clf.predict(X_test) for clf in clfs]
y_scores = np.array([accuracy_score(y_test, y_pred) for y_pred in y_preds])
print("Accuracy after pruning:", np.max(y_scores))

# Экспорт текста дерева решений после прунинга
best_clf = clfs[np.argmax(y_scores)]
r_after = export_text(best_clf, feature_names=data.feature_names.tolist())
print("Decision tree after pruning:\n", r_after)
```

Этот код демонстрирует процесс обучения дерева решений без прунинга и после него, а также оценку точности модели до и после применения прунинга.